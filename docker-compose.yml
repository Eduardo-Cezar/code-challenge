version: '3'

services:
  db:
    image: postgres:12
    environment:
      POSTGRES_DB: northwind
      POSTGRES_USER: northwind_user
      POSTGRES_PASSWORD: thewindisblowing
    volumes:
      - ./dbdata:/var/lib/postgresql/data
      - ./data/northwind.sql:/docker-entrypoint-initdb.d/northwind.sql
    ports:
      - 5432:5432

  db_transformed:
    image: postgres:12
    environment:
      POSTGRES_DB: northwind_transformed
      POSTGRES_USER: northwind_user
      POSTGRES_PASSWORD: thewindisblowing
    volumes:
      - ./dbdata_transformed:/var/lib/postgresql/data
    ports:
      - 5433:5432
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U northwind_user -d northwind_transformed"]
      interval: 10s
      timeout: 5s
      retries: 5

  meltano:
    build:
      context: .
      dockerfile: Dockerfile.meltano
    working_dir: /project
    depends_on:
      - db
      - db_transformed
    environment:
      - MELTANO_DATABASE_URI=postgresql://northwind_user:thewindisblowing@db:5432/northwind
      - MELTANO_TRANSFORMED_URI=postgresql://northwind_user:thewindisblowing@db_transformed:5432/northwind_transformed
    volumes:
      - ./meltano:/project
      - ./data:/data
    ports:
      - "5000:5000"
    user: "1000:1000"
    entrypoint: ["bash", "-c"]
    command: |
      "
      # Aguardar o banco estar disponível
      echo 'Aguardando banco de dados transformado...'
      while ! pg_isready -h db_transformed -p 5432 -U northwind_user; do
        sleep 1
      done
      echo 'O banco de dados para os dados transformados está pronto para ser usado!'

      # Criar diretórios necessários
      mkdir -p /project/data/input /project/data/output

      # Copiar apenas order_details.csv
      cp /data/order_details.csv /project/data/input/ 2>/dev/null || echo 'Erro ao copiar order_details.csv'

      # Inicializar Meltano se necessário
      if [ ! -f 'meltano.yml' ]; then
        meltano init .
      fi

      # Manter o container rodando
      tail -f /dev/null
      "
    restart: always

  airflow-init:
    image: apache/airflow:2.7.1
    depends_on:
      - airflow-db
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db/airflow
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./meltano:/opt/airflow/meltano
    command: bash -c "
      airflow db init &&
      airflow users create \
        --username admin \
        --password admin \
        --firstname Admin \
        --lastname User \
        --role Admin \
        --email admin@example.com
      "

  airflow:
    image: apache/airflow:2.7.1
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db/airflow
      - AIRFLOW__WEBSERVER__SECRET_KEY=your_secret_key_here
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./meltano:/opt/airflow/meltano
    ports:
      - "8081:8080"
    command: webserver
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  airflow-scheduler:
    image: apache/airflow:2.7.1
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    environment:
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@airflow-db/airflow
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./meltano:/opt/airflow/meltano
    command: scheduler

  airflow-db:
    image: postgres:12
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - airflow-db-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5

volumes:
  airflow-db-data: